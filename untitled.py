# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GcX37df4zc5dEVZE_io2I04eRnppivSa
"""

#21BCE11093_PRASHANSA_JAIN
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
# Generate synthetic data for logistic regression
X_logistic, y_logistic = make_classification(n_samples=100, n_features=1, n_informative=1, n_redundant=0, n_clusters_per_class=1, random_state=42)
# Perform logistic regression using NumPy
X_b_logistic = np.c_[np.ones((100, 1)), X_logistic]  # Add a bias term
theta_best_logistic = np.linalg.inv(X_b_logistic.T.dot(X_b_logistic)).dot(X_b_logistic.T).dot(y_logistic)
# Plot the data and the logistic regression curve
plt.scatter(X_logistic, y_logistic, color='blue')
X_test_logistic = np.linspace(-3, 3, 300)
X_test_b_logistic = np.c_[np.ones((300, 1)), X_test_logistic]
y_prob_logistic = 1 / (1 + np.exp(-X_test_b_logistic.dot(theta_best_logistic)))
plt.plot(X_test_logistic, y_prob_logistic, color='red', linewidth=2)
plt.title('Logistic Regression (NumPy)')
plt.xlabel('X')
plt.ylabel('Probability')
plt.show()